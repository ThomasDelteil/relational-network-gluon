{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn,utils \n",
    "import mxnet.ndarray as F\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_COUNT = 4 # increase if you have more\n",
    "ctx = [mx.gpu(i) for i in range(GPU_COUNT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvInputModel(nn.HybridBlock):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(ConvInputModel,self).__init__(**kwargs)\n",
    "                \n",
    "        with self.name_scope():\n",
    "            self.conv1 = nn.Conv2D(channels=24,kernel_size=3,strides=2,padding=1,activation='relu')\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.conv2 = nn.Conv2D(channels=24,kernel_size=3,strides=2,padding=1,activation='relu')\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.conv3 = nn.Conv2D(channels=24,kernel_size=3,strides=2,padding=1,activation='relu')\n",
    "            self.bn3 = nn.BatchNorm()\n",
    "            self.conv4 = nn.Conv2D(channels=24,kernel_size=3,strides=2,padding=1,activation='relu')\n",
    "            self.bn4 = nn.BatchNorm()\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCOutputModel(nn.HybridBlock):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(FCOutputModel,self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.fc2 = nn.Dense(256)\n",
    "            self.fc3 = nn.Dense(10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        #return F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RN_Model(nn.HybridBlock):\n",
    "    def __init__(self,args,coord_tensor=None,**kwargs):\n",
    "        super(RN_Model,self).__init__(**kwargs)\n",
    "    \n",
    "        with self.name_scope():\n",
    "            self.conv = ConvInputModel()\n",
    "            \n",
    "            self.g_fc1 = nn.Dense(256,activation='relu')\n",
    "            self.g_fc2 = nn.Dense(256,activation='relu')\n",
    "            self.g_fc3 = nn.Dense(256,activation='relu')\n",
    "            self.g_fc4 = nn.Dense(256,activation='relu')\n",
    "            \n",
    "            self.f_fc1 = nn.Dense(256,activation='relu')\n",
    "            \n",
    "            \n",
    "            #self.coord_oi = gluon.Parameter('oi',shape=(args.batch_size,2))\n",
    "            #self.coord_oj = gluon.Parameter('oj',shape=(args.batch_size,2))\n",
    "            #self.coord_tensor = gluon.Parameter('coord_tensor',shape=(args['batch_size'],25,2))\n",
    "        \n",
    "            ##initialize\n",
    "            #self.coord_oi.intialize()\n",
    "            #self.coord_oj.intialize()\n",
    "            #self.coord_tensor.initialize(ctx=ctx)\n",
    "            self.fcout = FCOutputModel()\n",
    "            \n",
    "            \n",
    "\n",
    "    def forward(self,x,qst,coord_tensor):\n",
    "        \n",
    "        self.coord_tensor = coord_tensor\n",
    "\n",
    "        # prepare coord tensor\n",
    "        def cvt_coord(i):\n",
    "            return [(i/5-2)/2., (i%5-2)/2.]\n",
    "        \n",
    "        for i in range(25):\n",
    "             self.coord_tensor[:,i,:] = F.array( cvt_coord(i) )\n",
    "\n",
    "        \n",
    "        #input size = (64 * 3 * 75 * 75)\n",
    "        x = self.conv(x) ## x = (64 * 24 * 5 * 5)\n",
    "                \n",
    "        ##g part\n",
    "        mb = x.shape[0]\n",
    "        n_channels = x.shape[1]\n",
    "        d = x.shape[2]\n",
    "        \n",
    "        x_flat = x.reshape(shape=(mb,n_channels,d*d))\n",
    "        x_flat = F.swapaxes(x_flat,1,2) ## (64 * 25 * 24)\n",
    "        \n",
    "        ##add coordinates\n",
    "        x_flat = F.concat(x_flat,self.coord_tensor,dim=2)\n",
    "        #x_flat = F.concat(x_flat,np_coord_tensor,dim=2)\n",
    "        \n",
    "        ##add question\n",
    "        qst = qst.expand_dims(1)\n",
    "        qst = F.repeat(qst,repeats=25,axis=1)\n",
    "        qst =qst.expand_dims(2)\n",
    "        \n",
    "        # cast all pairs against each other\n",
    "        x_i = x_flat.expand_dims(1)\n",
    "        x_i = F.repeat(x_i,repeats=25,axis=1)\n",
    "        \n",
    "        x_j = x_flat.expand_dims(2)\n",
    "        x_j = F.concat(x_j,qst,dim=3)\n",
    "        x_j = F.repeat(x_j,repeats=25,axis=2)\n",
    "        \n",
    "        #concatenate all\n",
    "        x_full = F.concat(x_i,x_j,dim=3)\n",
    "        \n",
    "        #reshape and apply dnn network\n",
    "        x_ = x_full.reshape((-1,63))\n",
    "        x_ = self.g_fc1(x_)\n",
    "        x_ = self.g_fc2(x_)\n",
    "        x_ = self.g_fc3(x_)\n",
    "        x_ = self.g_fc4(x_)\n",
    "        \n",
    "        x_g = x_.reshape((mb,-1,256))\n",
    "        x_g = x_g.sum(1)\n",
    "        \n",
    "        ##### f part #######\n",
    "        x_f = self.f_fc1(x_g)\n",
    "        \n",
    "        return self.fcout(x_f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print('loading data...')\n",
    "    dirs = os.getcwd()\n",
    "    filename = os.path.join(dirs,'sort-of-clevr.pickle')\n",
    "    with open(filename, 'rb') as f:\n",
    "        train_datasets, test_datasets = pickle.load(f)\n",
    "    rel_train = []\n",
    "    rel_test = []\n",
    "    norel_train = []\n",
    "    norel_test = []\n",
    "    print('processing data...')\n",
    "\n",
    "    for img, relations, norelations in train_datasets:\n",
    "        img = np.swapaxes(img,0,2)\n",
    "        for qst,ans in zip(relations[0], relations[1]):\n",
    "            rel_train.append((img,qst,ans))\n",
    "        for qst,ans in zip(norelations[0], norelations[1]):\n",
    "            norel_train.append((img,qst,ans))\n",
    "\n",
    "    for img, relations, norelations in test_datasets:\n",
    "        img = np.swapaxes(img,0,2)\n",
    "        for qst,ans in zip(relations[0], relations[1]):\n",
    "            rel_test.append((img,qst,ans))\n",
    "        for qst,ans in zip(norelations[0], norelations[1]):\n",
    "            norel_test.append((img,qst,ans))\n",
    "    \n",
    "    return (rel_train, rel_test, norel_train, norel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "processing data...\n"
     ]
    }
   ],
   "source": [
    "rel_train, rel_test, norel_train, norel_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(data):\n",
    "    img = data[0]\n",
    "    img = np.swapaxes(img,0,2)\n",
    "    plt.imshow((img * 255.0).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f801cc20518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(rel_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "args['batch_size'] = 64\n",
    "args['epoches'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coord_tensor = F.zeros((args['batch_size'], 25, 2))\n",
    "#coord_tensor = gluon.utils.split_and_load(coord_tensor,ctx)\n",
    "model = RN_Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter initialozation\n",
    "model.collect_params().initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set optimizer\n",
    "trainer = gluon.Trainer(model.collect_params(),optimizer='adam',optimizer_params={'learning_rate':0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare coord tensor\n",
    "def cvt_coord(i):\n",
    "    return [(i/5-2)/2., (i%5-2)/2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_data_axis(data):\n",
    "    img = [e[0] for e in data]\n",
    "    qst = [e[1] for e in data]\n",
    "    ans = [e[2] for e in data]\n",
    "    return (img,qst,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_conv(data, i,bs):\n",
    "    img = F.array(np.asarray(data[0][bs*i:bs*(i+1)]))\n",
    "    qst = F.array(np.asarray(data[1][bs*i:bs*(i+1)]))\n",
    "    ans = F.array(np.asarray(data[2][bs*i:bs*(i+1)]))\n",
    "\n",
    "    return img, qst, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Evaluation metric\n",
    "def evaluate_accuracy(data,  model, ctx):\n",
    "    data_conv = cvt_data_axis(data)\n",
    "    acc = mx.metric.Accuracy()\n",
    "    accuracy_mat = []\n",
    "    for batch_idx in range(len(data) // (args['batch_size'])):\n",
    "        input_img, input_qst, label = ndarray_conv(data_conv,batch_idx,args['batch_size'])\n",
    "        input_img = input_img.as_in_context(ctx)\n",
    "        input_qst = input_qst.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        coord_tensor = F.zeros((args['batch_size'], 25, 2),ctx=ctx)\n",
    "        output = model(input_img,input_qst,coord_tensor)\n",
    "        predictions = nd.argmax(output,axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "        accuracy_mat.append(acc.get()[1])\n",
    "    accuracy = sum(accuracy_mat) / len(accuracy_mat)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(args['epoches'])):\n",
    "    cumulative_rel_loss = 0.0\n",
    "    cumulative_norel_loss = 0.0\n",
    "    \n",
    "    input_rel_train = rel_train.copy()\n",
    "    input_norel_train = norel_train.copy()\n",
    "    \n",
    "    #shuffle data\n",
    "    random.shuffle(input_rel_train)\n",
    "    random.shuffle(input_norel_train)\n",
    "    \n",
    "    rel = cvt_data_axis(input_rel_train)\n",
    "    norel = cvt_data_axis(input_norel_train)\n",
    "    \n",
    "    #for batch_idx in tqdm(range(len(rel[0]) // (args['batch_size'] * 4))):\n",
    "    for batch_idx in range(len(rel[0]) // (args['batch_size']*4)):\n",
    "        input_rel_img, input_rel_qst, rel_label = ndarray_conv(rel,batch_idx,args['batch_size']*4)\n",
    "        \n",
    "        #data split\n",
    "        input_rel_img = gluon.utils.split_and_load(input_rel_img,ctx)\n",
    "        input_rel_qst = gluon.utils.split_and_load(input_rel_qst,ctx)\n",
    "        rel_label = gluon.utils.split_and_load(rel_label,ctx)\n",
    "        coord_tensor = F.zeros((args['batch_size'] * 4, 25, 2))\n",
    "        coord_tensor = gluon.utils.split_and_load(coord_tensor,ctx)\n",
    "        with autograd.record():\n",
    "            rel_losses = [loss(model(X,Y,W),Z) for X, Y, W, Z in zip(input_rel_img,input_rel_qst,coord_tensor,rel_label)]\n",
    "        for l in rel_losses:\n",
    "            l.backward()\n",
    "        trainer.step(args['batch_size'])\n",
    "        for l in rel_losses:\n",
    "            cumulative_rel_loss += nd.sum(l).asscalar()\n",
    "\n",
    "        \n",
    "        input_norel_img, input_norel_qst, norel_label = ndarray_conv(norel,batch_idx,args['batch_size']*4)  \n",
    "        \n",
    "        #data split\n",
    "        input_norel_img = gluon.utils.split_and_load(input_norel_img,ctx)\n",
    "        input_norel_qst = gluon.utils.split_and_load(input_norel_qst,ctx)\n",
    "        norel_label = gluon.utils.split_and_load(norel_label,ctx)\n",
    "        with autograd.record():\n",
    "            norel_losses = [loss(model(X,Y,W),Z) for X, Y, W, Z in zip(input_norel_img,input_norel_qst,coord_tensor,norel_label)]\n",
    "        for l in norel_losses:\n",
    "            l.backward()\n",
    "        trainer.step(args['batch_size']*4)\n",
    "        for l in rel_losses:\n",
    "            cumulative_norel_loss += nd.sum(l).asscalar()\n",
    "            \n",
    "    rel_accuracy = evaluate_accuracy(rel_test, model, mx.gpu(0))\n",
    "    norel_accuracy = evaluate_accuracy(norel_test, model, mx.gpu(0))\n",
    "    #print(\"Epoch {e}. rel_Loss: {rl} \".format(e=epoch, rl=cumulative_loss/(len(rel[0]) // (args['batch_size']))))\n",
    "    print(\"Epoch {e}. rel_Loss: {rl} norel_Loss: {nrl} rel_ACC: {rl_acc} norel_ACC: {nrl_acc}\".format(e=epoch, rl=cumulative_rel_loss/(len(rel[0]) // args['batch_size'])\n",
    "                                                                                                      , nrl=cumulative_norel_loss/ (len(rel[0]) // args['batch_size']), rl_acc=rel_accuracy,nrl_acc=norel_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RN_Model(\n",
       "  (conv): ConvInputModel(\n",
       "    (conv1): Conv2D(3 -> 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=24)\n",
       "    (conv2): Conv2D(24 -> 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=24)\n",
       "    (conv3): Conv2D(24 -> 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=24)\n",
       "    (conv4): Conv2D(24 -> 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=24)\n",
       "  )\n",
       "  (g_fc1): Dense(63 -> 256, Activation(relu))\n",
       "  (g_fc2): Dense(256 -> 256, Activation(relu))\n",
       "  (g_fc3): Dense(256 -> 256, Activation(relu))\n",
       "  (g_fc4): Dense(256 -> 256, Activation(relu))\n",
       "  (f_fc1): Dense(256 -> 256, Activation(relu))\n",
       "  (fcout): FCOutputModel(\n",
       "    (fc2): Dense(256 -> 256, linear)\n",
       "    (fc3): Dense(256 -> 10, linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save the model\n",
    "filename = os.getcwd()+'/models/rl_multi_gpu.params'\n",
    "model.save_params(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
